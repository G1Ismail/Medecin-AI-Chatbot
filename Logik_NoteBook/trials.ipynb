{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /Users/i.g/Documents/Medecin-AI-Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "MeinLLM = OpenAI(temperature=0.9, max_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPdfDoc(data):\n",
    "    loader = DirectoryLoader(data, glob='*.pdf', loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractedData = loadPdfDoc(data='Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datein in klieneren Chunks splitten:\n",
    "\n",
    "def textSplit(extractedData):\n",
    "    textSpitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap=20)\n",
    "    textChunks = textSpitter.split_documents(extractedData)\n",
    "    return textChunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textChunks = textSplit(extractedData=extractedData)\n",
    "print(\"Length of text Chunks\", len(textChunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Herunterladen von einem Embedding Model von HuggingFace:\n",
    "def downloadHuggingFace_Embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = downloadHuggingFace_Embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eine Pinecone cluster erstellen:\n",
    "\n",
    "pc =  Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "pc.create_index(\n",
    "    name=\"medicin-chat-bot\", # Ich hatte ein Problem hier: nach lange Suche --> Losüng: keine Uppercases sind in Pinecone Indexes erlaubt\n",
    "    dimension=384, # diese Dimension entspricht die Dimension vom HugginfFace Model, es ist sehr wichtig auf diese Dimension zu achten (Falls zukünftig anderes Model)\n",
    "    metric=\"cosine\", # andere metrics z.B: euclidean ... \n",
    "    spec=ServerlessSpec(\n",
    "        # diese Specs sind die einzigen die gratis sind\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Chunks embedden --> Chunks sind jetzt Vektoren und eine VektorStore (DatenBank) ist dafür nötig --> PineconeVectorStore\n",
    "\n",
    "docSearch = PineconeVectorStore.from_documents(\n",
    "    documents=textChunks,\n",
    "    index_name=\"medicin-chat-bot\",\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load existierendes Pinecone Index:\n",
    "\n",
    "docSearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=\"medicin-chat-bot\",\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docSearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hier wird der OpenAI LLM model benutzt, um die vernünftige, richige und gezielte Ergebnisse zu bekommen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "System_Prompt = (\n",
    "    \"You are a medical assistant for question-answering tasks related to the medical field.\"\n",
    "    \"Use only the following pieces of retrieved context to answer the questions you get asked \"\n",
    "    \"and nothing else. If you don't know the answer, say that you don't know.\"\n",
    "    \"Keep the answers concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", System_Prompt),\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(MeinLLM, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer = rag_chain.invoke({\"input\":\"my fever is high, i am coughing the hole time, my nose is closed and i keep spitting mucus, what do i have and what medecine should i take\"}) \n",
    "print(Answer[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIChatBotVEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
